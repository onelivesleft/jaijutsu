// @Cleanup: Explicitly check against end-of-input for all sub-lexers.

#import "Basic";
#import "Pool";
#import "File";
#import "Unicode";

USE_SIMD :: false;

MAX_IDENTIFIER_LENGTH :: 512;
MAX_CONCURRENT_TOKENS :: 8;  // Must be a power of two!  // @Cleanup: explain why or change.
LEXER_SIMD_WIDTH :: 16;

// @Cleanup: Add zero-termination as an option?

Token_Type :: enum s16 {
    // Mentally insert ASCII types here

    NEWLINE :: #char "\n";
    BANG :: #char "!";
    DOUBLE_QUOTE :: #char "\"";
    HASH :: #char "#";
    DOLLAR :: #char "$";
    PERCENT :: #char "%";
    AMPERSAND :: #char "&";
    SINGLE_QUOTE :: #char "'";
    OPEN_PAREN :: #char "(";
    CLOSE_PAREN :: #char ")";
    ASTERISK :: #char "*";
    PLUS :: #char "+";
    COMMA :: #char ",";
    MINUS :: #char "-";
    PERIOD :: #char ".";
    SLASH :: #char "/";
    DIGIT_0 :: #char "0";
    DIGIT_1 :: #char "1";
    DIGIT_2 :: #char "2";
    DIGIT_3 :: #char "3";
    DIGIT_4 :: #char "4";
    DIGIT_5 :: #char "5";
    DIGIT_6 :: #char "6";
    DIGIT_7 :: #char "7";
    DIGIT_8 :: #char "8";
    DIGIT_9 :: #char "9";
    COLON :: #char ":";
    SEMICOLON :: #char ";";
    LESSTHAN :: #char "<";
    EQUALS :: #char "=";
    GREATERTHAN :: #char ">";
    QUESTION :: #char "?";

    OPEN_BRACKET :: #char "[";
    BACKSLASH :: #char "\\";
    CLOSE_BRACKET :: #char "]";
    UNDERSCORE :: #char "_";
    BACKTICK :: #char "`";

    OPEN_BRACE :: #char "{";
    PIPE :: #char "|";
    CLOSE_BRACE :: #char "}";

    BITWISE_XOR :: #char "^";
    BITWISE_NOT :: #char "~";
    BITWISE_AND :: #char "&";
    BITWISE_OR  :: #char "|";


    IDENT :: 256;
    NUMBER :: 257;
    STRING :: 258;

    PLUSEQUALS :: 259;
    MINUSEQUALS :: 260;
    TIMESEQUALS :: 261;
    DIVEQUALS :: 262;
    MODEQUALS :: 263;
    ISEQUAL :: 264;
    ISNOTEQUAL :: 265;
    LOGICAL_AND :: 266;
    LOGICAL_OR :: 267;
    LESSEQUALS :: 268;
    GREATEREQUALS :: 269;

    RIGHT_ARROW :: 270;
    DOUBLE_DOT :: 271;
    DOUBLE_DOLLAR :: 272;

    SHIFT_LEFT  :: 273;
    SHIFT_RIGHT :: 274;

    ROTATE_LEFT         :: 275;  // This is not actually generated by the lexer; it's disambiguated by the parser when we decide the operator is unary or binary.  -jblow; 25 April 2021.
    ROTATE_RIGHT        :: 276;

    TRIPLE_EQUALS       :: 277;  // Used for #asm register pinning; currently.

    SHIFT_LEFT_EQUALS   :: 290;
    SHIFT_RIGHT_EQUALS  :: 291;

    ROTATE_LEFT_EQUALS  :: 292;
    ROTATE_RIGHT_EQUALS :: 293;

    BITWISE_AND_EQUALS  :: 294;
    BITWISE_OR_EQUALS   :: 295;
    BITWISE_XOR_EQUALS  :: 296;

    LOGICAL_AND_EQUALS  :: 297;
    LOGICAL_OR_EQUALS   :: 298;

    POINTER_DEREFERENCE :: 310;
    POSTFIX_DEREFERENCE :: 311;
    CONDITIONAL_DEREFERENCE;
    ISEQUAL_FOR_SWITCH_STATEMENT;

    DOUBLE_MINUS;
    TRIPLE_MINUS;

    DOUBLE_COMMA;

    BEGIN_STRUCT_LITERAL;
    BEGIN_ARRAY_LITERAL;

    KEYWORD_FOR;
    __FIRST_KEYWORD :: KEYWORD_FOR; // Used for a parse error message or two.
    KEYWORD_IF;
    KEYWORD_IFX;
    KEYWORD_THEN;
    KEYWORD_ELSE;
    KEYWORD_CASE;
    KEYWORD_RETURN;
    KEYWORD_STRUCT;
    KEYWORD_WHILE;
    KEYWORD_BREAK;
    KEYWORD_CONTINUE;
    KEYWORD_REMOVE;
    KEYWORD_USING;

    KEYWORD_DEFER;
    KEYWORD_SIZE_OF;
    KEYWORD_TYPE_OF;
    KEYWORD_CODE_OF;
    KEYWORD_INITIALIZER_OF;
    KEYWORD_TYPE_INFO;
    KEYWORD_NULL;

    KEYWORD_ENUM;
    KEYWORD_TRUE;
    KEYWORD_FALSE;

    KEYWORD_INLINE;
    KEYWORD_NO_INLINE;

    KEYWORD_CAST;
    KEYWORD_AUTO_CAST;

    KEYWORD_CONTEXT;
    KEYWORD_PUSH_CONTEXT;
    KEYWORD_OPERATOR;
    KEYWORD_IS_CONSTANT;

    KEYWORD_ENUM_FLAGS;
    KEYWORD_UNION;
    KEYWORD_INTERFACE;

    __LAST_KEYWORD :: KEYWORD_INTERFACE;

    QUICK_LAMBDA;

    NOTE;

    END_OF_INPUT;

    POINTER_DEREFERENCE_OR_SHIFT_LEFT;

    OPERATOR_ARRAY_SUBSCRIPT :: 500;  // Not actually an input token.  It's here so that it can
                                           // be used as an 'operator_type' in Ast_Binary.  Ugh...
    OPERATOR_ASSIGNMENT_TO_ARRAY_SUBSCRIPT :: 501;

    ERROR;
};

Note_Flags :: enum_flags u8 {
    IS_SYSTEM_LEVEL :: 0x1;
}

Table_String :: #type,isa string;

Value_Flags :: enum_flags u32 {
    HERE_STRING      :: 0x1;
    NUMBER           :: 0x2;
    HEX              :: 0x4;
    BINARY           :: 0x8;
    FLOAT            :: 0x10;

    REQUIRES_FLOAT64    :: 0x10_0000;
    DEFAULTS_TO_FLOAT64 :: 0x20_0000;
    REQUIRES_FLOAT64_DUE_TO_SIGNIFICANT_DIGITS :: 0x40_0000;

    OVERFLOWED       :: 0x1000_0000;
}

Token :: struct {
    type: Token_Type = .ERROR;

    l0, c0: s32;
    l1, c1: s32 = -1;

    union {
        ident\ _value: struct { name: Table_String; hash: u32; };
        integer_value: u64;
        float64_value: float64;
        string\_value: string;
    };

    value_flags: Value_Flags;  // If a number or a note. Mostly the old numeric_flags, but also has HERESTRING now.
    ident_is_backticked := false;
}

Lexer :: struct {
    current_line_number: s32;
    current_external_file_error_report_line_number: s32;
    current_character_index: s32;

    atom_pool:  Pool;
//    atom_table: Table(string, Table_String);

    tokens: [MAX_CONCURRENT_TOKENS] Token;
    token_array_cursor:  s32;
    num_incoming_tokens: s32;

    input: string;
    input_cursor: s64;

    should_free_input := false;
    total_lines_processed:    s64;
    nonblank_lines_processed: s64;

    previous_token_line_number: s64;

    eof_token: Token;  // This is maybe not necessary; we could just allocate a new token from the ring buffer!
    eof_token.type = .END_OF_INPUT;

    user_data: *void;

    scratch_buffer: [MAX_IDENTIFIER_LENGTH] u8;

    reported_error := false;
}

peek_next_token :: (using lexer: *Lexer) -> *Token {
    if num_incoming_tokens {
        assert(tokens[token_array_cursor].l1 != -1);
        return *tokens[token_array_cursor];
    }

    compose_new_token(lexer);
    num_incoming_tokens += 1;

    assert(tokens[token_array_cursor].l1 != -1);
    return *tokens[token_array_cursor];
}

get_last_token :: (lexer: *Lexer) -> Token {
    // This returns to you the last accepted token (that you called eat_token on). You're allowed to do this as long
    // as you know you didn't fill all the slots with read-ahead un-accepted tokens.

    cursor := lexer.token_array_cursor;

    // Wrap backwards...  Note we are not using the power-of-two requirement here, @Cleanup: Remove that constraint?
    if cursor  cursor -= 1;
    else       cursor = MAX_CONCURRENT_TOKENS - 1;

    return lexer.tokens[cursor];
}


starts_identifier :: inline (c: u8) -> bool {
    if is_alpha(c)     return true;
    if c == #char "_"  return true;
    return false;
}


Hex_Digit_Type :: enum u8 {
    ASCII_8_BIT :: 0;
    UNICODE_16  :: 1;
    UNICODE_32  :: 2;
}

cached_make_atom :: (lexer: *Lexer, name: string, token_to_fill: *Token) {
    /* @Cleanup
    table := *lexer.active_load.atom_table;
    name_atom := nonlocked_make_atom(table, *lexer.atom_pool, name, *token_to_fill.ident_value.hash);
    token_to_fill.ident_value.name = name_atom;
*/

    token_to_fill.ident_value.name = cast(Table_String) copy_string(name);
}

eat_character :: (using lexer: *Lexer) {
    if input.data[input_cursor] == #char "\n" {
        // :DoThisOnNewline
        current_line_number += 1;
        total_lines_processed += 1;
        current_character_index = 0;  // Will get incremented to 1 below.
    }

	input_cursor += 1;
    current_character_index += 1;
}


peek_next_character :: (lexer: *Lexer) -> s16 {
    if (lexer.input_cursor >= lexer.input.count) {
        return -1;
    }

    result := lexer.input.data[lexer.input_cursor];
    return result;
}


report_parse_error :: (lexer: *Lexer, format: string, arguments: .. Any) {
    // @Cleanup: Put the file and line number here.
    log(format, .. arguments);  // @Cleanup: Move this function, make it user-overridable.
    lexer.reported_error = true;
} @PrintLike

report_parse_error :: (lexer: *Lexer, token: *Token, format: string, arguments: .. Any) {
    // @Cleanup: use token to put the file and line number here.
    log(format, .. arguments);  // @Cleanup: Move this function, make it user-overridable.
    lexer.reported_error = true;
} @PrintLike

report_detail :: (lexer: *Lexer, format: string, arguments: .. Any) {
    log(format, .. arguments);  // @Cleanup: Move this function, make it user-overridable.
} @PrintLike

get_hex_digit :: (lexer: *Lexer, type: Hex_Digit_Type) -> (value: u8, success: bool) {
    c := peek_next_character(lexer);

    if      (c >= #char "a") && (c <= #char "f") { eat_character(lexer); return cast(u8)(10 + c - #char "a"), true; }
    else if (c >= #char "A") && (c <= #char "F") { eat_character(lexer); return cast(u8)(10 + c - #char "A"), true; }
    else if (c >= #char "0") && (c <= #char "9") { eat_character(lexer); return cast(u8)(c - #char "0"), true; }

    report_parse_error(lexer, "A hex digit is required here.\n");

    if type == {
    case .ASCII_8_BIT;
        report_detail(lexer, "\\x must be followed by exactly two hex digits.\n");
    case .UNICODE_16;
        report_detail(lexer, "\\u must be followed by exactly four hex digits.\n");
    case .UNICODE_32;
        report_detail(lexer, "\\U must be followed by exactly eight hex digits.\n");
    }

    return 0, false;
}

get_decimal_digit :: (lexer: *Lexer) -> s32 {
    c := peek_next_character(lexer);

    if (c >= #char "0") && (c <= #char "9") {
        eat_character(lexer);
        return c - #char "0";
    }

    report_parse_error(lexer, "A decimal digit is required here.\n");
    report_detail(lexer, "\\d must be followed by exactly three decimal digits.\n");

    return -1;
}

set_end_of_token :: (lexer: *Lexer, token: *Token) {
    token.l1 = lexer.current_line_number;
    token.c1 = lexer.current_character_index;
}

unwind_one_character :: (lexer: *Lexer) {
    assert(lexer.input_cursor != 0);
    lexer.input_cursor -= 1;
    lexer.current_character_index -= 1;
}


continues_identifier :: (c: s32) -> bool {
    return is_alnum(xx c) || (c == #char "_");
}

starts_number :: (c: s32) -> bool {
    return is_digit(cast(u8) c);
}

get_unused_token :: (lexer: *Lexer) -> *Token {
    assert(lexer.num_incoming_tokens < MAX_CONCURRENT_TOKENS);

    index := (lexer.token_array_cursor + lexer.num_incoming_tokens) & (MAX_CONCURRENT_TOKENS - 1);
    result := *lexer.tokens[index];

    result.l0            = lexer.current_line_number;
    result.c0            = lexer.current_character_index;
    result.type          = .ERROR;
    result.value_flags   = 0;
    result.ident_is_backticked = false;

    return result;
}

parse_ident :: (lexer: *Lexer, result: *Token) -> string {
    buffer := lexer.scratch_buffer.data;
    scratch_pos := buffer;

    mask: s32;

    /*
#if USE_SIMD
    __m128i zero   = _mm_set1_epi8("0"-1); // Because we don"t have le and ge in SSE2? We just have lt and gt??
    __m128i nine   = _mm_set1_epi8("9"+1);
    __m128i under  = _mm_set1_epi8("_");
    __m128i a      = _mm_set1_epi8("A"-1);
    __m128i z      = _mm_set1_epi8("Z"+1); // See above.
    __m128i not32  = _mm_set1_epi8((char)(255-32));

    while (lexer.input.count - lexer.input_cursor >= LEXER_SIMD_WIDTH) {
        __m128i characters = _mm_loadu_si128  ((__m128i *)(lexer.input.data + lexer.input_cursor));
        __m128i toupper    = _mm_and_si128    (characters, not32);

        // In AVX-512 we can compare into 16-bit masks and do booleans on those,
        // but, not in SSE.

        __m128i geq_A      = _mm_cmpgt_epi8 (toupper, a);
        __m128i leq_Z      = _mm_cmplt_epi8 (toupper, z);
        __m128i _isalpha   = _mm_and_si128  (geq_A, leq_Z);
        __m128i geq_0      = _mm_cmpgt_epi8 (characters, zero);
        __m128i leq_9      = _mm_cmplt_epi8 (characters, nine);
        __m128i _isnum     = _mm_and_si128  (geq_0, leq_9);
        __m128i _isunder   = _mm_cmpeq_epi8 (characters, under);

        __m128i _isalnum   = _mm_or_si128   (_isalpha, _isnum);
        __m128i is_ident   = _mm_or_si128   (_isalnum, _isunder);

        mask               = _mm_movemask_epi8(is_ident);

        // This mask xor is probably wasteful. We can DeMorgan all this later, or something.
        // We"re doing this because we detected what *is* in an identifier, rather than what
        // is not.
        mask ^= 0xffff;

        s64 advance;
        if (mask) {
            advance = _tzcnt_u32(mask);
        } else {
            advance = 16;
        }

        advance = Min(advance, MAX_TOKEN_LENGTH - (scratch_pos - buffer));  // :IdentTooLong  @Robustness: Report an error here about ident too long.
        assert(advance >= 0);

        // @Speed: Instead of this memcpy, can we just do a move into the
        // scratch buffer? (Don"t even need a partial move if we give the
        // scratch buffer LEXER_SIMD_WIDTH extra padding.)
        memcpy(scratch_pos, lexer.input.data + lexer.input_cursor, advance);
        scratch_pos  += advance;
		lexer.input_cursor += advance;
        lexer.current_character_index += temporary_truncate_to_s32(advance);

        if (mask) break;  // If mask != 0, we found a non-identifier character.
    }
#endif
*/

    // For now we punt and go into slow mode on a backslash:
    c := peek_next_character(lexer);
    if (!mask) || (c == #char "\\") while 1 {
        if scratch_pos - buffer == MAX_IDENTIFIER_LENGTH - 1 {
            // :IdentTooLong
            // @Robustness: Report an error here about ident too long
            // and maybe just eat the rest of the ident.
            break;
        }

        c := peek_next_character(lexer);
        if continues_identifier(c) {
            eat_character(lexer);
            <<scratch_pos = cast(u8) c;
            scratch_pos += 1;
            continue;
        } else if c == #char "\\" {
            eat_character(lexer);
            while 1 {
                c := peek_next_character(lexer);
                if c == #char " " {
                    eat_character(lexer);
                } else {
                    break;
                }
            }

            continue;
        }

        break;
    }

    set_end_of_token(lexer, result);

    <<scratch_pos = 0;
    scratch_pos += 1;

    length := cast(s32)(scratch_pos - buffer);
    assert(length <= MAX_IDENTIFIER_LENGTH);

    s: string;
    s.data  = buffer;
    s.count = length-1;  // Don't count the zero!

    return s;
}

parse_here_string :: (lexer: *Lexer) -> *Token {
    assert(lexer.num_incoming_tokens == 0);  // The parser should not be in a state where later characters have been processed into tokens.

    c := peek_next_character(lexer);

    // Eat whitespace.
    while is_space(cast(u8) c) {
        eat_character(lexer);
        c = peek_next_character(lexer);
    }

    want_cr := false;
    if c == #char "," {
        eat_character(lexer);
        ident_token := peek_next_token(lexer);
        if ident_token.type != .IDENT {
            report_parse_error(lexer, ident_token, "Expected an identifier after ','.\n");
            return null;
        }

        name := ident_token.ident_value.name;
        if name == "cr" {
            want_cr = true;
        } else {
            report_parse_error(lexer, ident_token, "Invalid #string modifier after ','.\n");
            return null;
        }

        eat_token(lexer);
        assert(lexer.num_incoming_tokens == 0);  // The parser should not be in a state where later characters have been processed into tokens.

        c = peek_next_character(lexer);

        // Eat whitespace.
        while is_space(cast(u8) c) {
            eat_character(lexer);
            c = peek_next_character(lexer);
        }
    }

    if !starts_identifier(cast(u8) c) {
        report_parse_error(lexer, "Expected identifier after #string.\n");
        return null;
    }


    result := get_unused_token(lexer);
    ident := parse_ident(lexer, result);

    ident_len := ident.count;
    assert(ident_len > 0);

    // Eat whitespace until newline.
    while 1 {
        c := peek_next_character(lexer);

        if c == -1 {
            report_parse_error(lexer, "Reached end-of-file in #string.\n");
            return null;
        }

        if !is_space(cast(u8) c) {
            report_parse_error(lexer, "Unexpected non-whitespace characters after #string identifier.\n");
            return null;
        }

        eat_character(lexer);

        if c == #char "\n" {
            // eat_character advances current_line_number.
            //got_newline = true;
            break;
        }
    }

    // Now we are reading the actual string:
    cursor := lexer.input_cursor;

    string_start := cursor;
    string_end   := cursor;

    result.l0 = lexer.current_line_number;
    result.c0 = lexer.current_character_index;

    got_terminating_ident    := false;
    contains_carriage_return := false;
    while 1 {
        // Keep reading lines. First we check to match the ident. If we don"t succeed at this,
        // scan until the next newline and repeat.

        // This code depends on us having the entire file in memory at once.

        if cursor >= lexer.input.count {
            report_parse_error(lexer, "Unexpected end of file inside #string.\n");
            return null;
        }

        cursor_at_start_of_line := cursor;

        // IC: I"d like to skip whitespaces at the beginning of the line that contains the terminator so that it can be indented.
        while 1 {
            c := lexer.input.data[cursor];
            if c == #char "\n" break; // exit the loop at the first newline to ensure current_line_number gets updated!
            if !is_space(cast(u8) c) break;
            cursor += 1;
        }

        remaining := lexer.input.count - cursor;
        if remaining >= ident_len {
            // @Speed...
            input_remaining := lexer.input.count - cursor;
            if input_remaining >= ident_len {
                if memcmp(lexer.input.data + cursor, ident.data, ident_len) == 0 {
                    cursor += ident_len;
                    if (remaining == ident_len) || !continues_identifier(<<(lexer.input.data + cursor)) {
                        got_terminating_ident = true;
                        lexer.current_character_index = cast(s32)(ident_len) + 1;
                        break;
                    }
                }
            }
        }

        // We didn"t match the ident, so let"s scan to a newline
        // and continue.

        while cursor < lexer.input.count {
            c := cast(s32) lexer.input.data[cursor];

            // Don"t break on zero! There could be a zero in the source file for all you know.  if (c == 0) break;

            if c == #char "\r" {
                contains_carriage_return = true;
            } else if c == #char "\n" {
                cursor += 1;
                string_end = cursor;

                // It"s a little wasteful, but we set the line and character
                // number for the end of the token every line. Maybe there"s
                // a cleaner way to do it.

                // set_end_of_token(result);
                result.l1 = lexer.current_line_number;
                result.c1 = cast(s32)(cursor - cursor_at_start_of_line);

                lexer.current_line_number += 1;
                lexer.total_lines_processed += 1;
                lexer.current_character_index = 0;

                break;
            }

            cursor += 1;
        }
    }

    net_lines := count_herestring_lines(lexer, result);  // @Speed: Why are we counting in a post-pass, when we already had to look at each character??

    // The here-string goes from string_start to string_end. (cursor is where we resume afterward).

    assert(cursor >= string_start);
    len := string_end - string_start;

    result_string: string;
    if want_cr {
        // Insert \r before every \n if there isn’t one already
        result_string = alloc_string(len+net_lines+1); // Add space for one \r per line. We might waste a few bytes here if there are alreay some \r in the string, but we don’t want to do a pre-pass to figure out how many we can save.
        dest := result_string.data;
        chunk_start := lexer.input.data + string_start;
        end := lexer.input.data + string_end;
        chunk_cur := chunk_start;

        while chunk_cur < end {
            c := <<chunk_cur;
            if (c == #char "\n") && (chunk_cur == chunk_start || <<(chunk_cur - 1) != #char "\r") {
                chunk_size := chunk_cur - chunk_start;
                memcpy(dest, chunk_start, chunk_size);
                dest += chunk_size + 2;
                <<(dest - 2) = #char "\r";
                <<(dest - 1) = #char "\n";
                chunk_cur += 1;
                chunk_start = chunk_cur;
                len += 1;
            }

            chunk_cur += 1;
        }

        chunk_size := chunk_cur - chunk_start;
        memcpy(dest, chunk_start, chunk_size);
    } else if contains_carriage_return {
        // Remove \r before every \n if there is one
        result_string = alloc_string(len+1); // We waste a few bytes here but we don’t want to do a pre-pass to figure out how many we can save.
        dest := result_string.data;

        chunk_start := lexer.input.data + string_start;
        end := lexer.input.data + string_end;
        chunk_cur := chunk_start;
        while chunk_cur < end {
            c := cast(s32) <<chunk_cur;
            if (c == #char "\r" && chunk_cur < end - 1 && <<(chunk_cur + 1) == #char "\n") {
                chunk_size := chunk_cur - chunk_start;
                memcpy(dest, chunk_start, chunk_size);
                dest += chunk_size;
                chunk_cur += 1;
                chunk_start = chunk_cur;
                len -= 1;
            }

            chunk_cur += 1;
        }

        chunk_size := chunk_cur - chunk_start;
        memcpy(dest, chunk_start, chunk_size);

    } else {
        // No need to normalize, just copy everything at once
        result_string = alloc_string(len+1); // We waste a few bytes here but we don’t want to do a pre-pass to figure out how many we can save.
        memcpy(result_string.data, lexer.input.data + string_start, len);
    }

    result_string[len]  = 0;    // :ZeroTermination
    assert(result_string.count >= len);  // I hope we had enough space!
    result_string.count = len;  // :ZeroTermination

    lexer.input_cursor = cursor;

    result.type = .STRING;
    result.string_value.count = len;
    result.value_flags |= .HERE_STRING;

    if len {
        result.string_value = cast(Table_String) result_string;
    } else {
        result.string_value = "";
    }

    return result;
}

make_note :: (lexer: *Lexer) -> *Token {
    note := get_unused_token(lexer);
    note.type = .NOTE;

    // Start and end indices do not include the leading @.

    name := parse_note(lexer);
    cached_make_atom(lexer, name, note);
    free(name);

    set_end_of_token(lexer, note);

    return note;
}

parse_note :: (lexer: *Lexer) -> string {
    input_cursor_orig := lexer.input_cursor;

    while lexer.input_cursor < lexer.input.count {
        c := lexer.input.data[lexer.input_cursor];
        if (c == #char " ") || (c == 9) || (c == 10) || (c == 13) || (c == 0) || (c == #char ";") { // Any whitespace, or semicolon.
            break;
        }

        lexer.input_cursor += 1;
    }

    len := lexer.input_cursor - input_cursor_orig;
    if len == 0 {
        report_parse_error(lexer, "Empty note.\n");
    }

    lexer.current_character_index += cast(s32) len;

    // @Speed: Don't dynamically allocate here.
    result := alloc_string(len+1);
    memcpy(result.data, lexer.input.data + input_cursor_orig, len);
    result[len] = 0;

    return result;
}

check_for_keyword :: (token: *Token) -> Token_Type {  // Returns Token_Type 0 if it is not a keyword.
    name   := token.ident_value.name;
    length := name.count;

    // @Speed: Since we already have the atom, then instead of doing strcmps,
    // we could just have a bunch of pre-looked-up atoms: atom_if, atom_then, etc...
    // then we just do a pointer compare and we know which keyword it is.

    if length == {
    case 2;
        if name == "if" return .KEYWORD_IF;
        if name == "xx" return .KEYWORD_AUTO_CAST;
        return 0;
    case 3;
        if name == "ifx" return .KEYWORD_IFX;
        if name == "for" return .KEYWORD_FOR;
        return 0;
    case 4;
        if name == "then" return .KEYWORD_THEN;
        if name == "else" return .KEYWORD_ELSE;
        if name == "null" return .KEYWORD_NULL;
        if name == "case" return .KEYWORD_CASE;
        if name == "enum" return .KEYWORD_ENUM;
        if name == "true" return .KEYWORD_TRUE;
        if name == "cast" return .KEYWORD_CAST;
        return 0;
    case 5;
        if name == "while" return .KEYWORD_WHILE;
        if name == "break" return .KEYWORD_BREAK;
        if name == "using" return .KEYWORD_USING;
        if name == "defer" return .KEYWORD_DEFER;
        if name == "false" return .KEYWORD_FALSE;
        if name == "union" return .KEYWORD_UNION;
        return 0;
    case 6;
        if name == "return" return .KEYWORD_RETURN;
        if name == "struct" return .KEYWORD_STRUCT;
        if name == "remove" return .KEYWORD_REMOVE;
        if name == "inline" return .KEYWORD_INLINE;
        return 0;
    case 7;
        if name == "size_of" return .KEYWORD_SIZE_OF;
        if name == "type_of" return .KEYWORD_TYPE_OF;
        if name == "code_of" return .KEYWORD_CODE_OF;
        if name == "context" return .KEYWORD_CONTEXT;
        return 0;
    case 8;
        if name == "continue" return .KEYWORD_CONTINUE;
        if name == "operator" return .KEYWORD_OPERATOR;
        return 0;
    case 9;
        if name == "type_info" return .KEYWORD_TYPE_INFO;
        if name == "no_inline" return .KEYWORD_NO_INLINE;
        if name == "interface" return .KEYWORD_INTERFACE;
        return 0;
    case 10;
        if name == "enum_flags" return .KEYWORD_ENUM_FLAGS;
        return 0;
    case 11;
        if name == "is_constant" return .KEYWORD_IS_CONSTANT;
        return 0;
    case 12;
        if name == "push_context" return .KEYWORD_PUSH_CONTEXT;
        return 0;
    case 14;
        if name == "initializer_of" return .KEYWORD_INITIALIZER_OF;
        return 0;
    case;
        return 0;
    }

    return 0;
}

make_ident_or_keyword :: (lexer: *Lexer) -> *Token {
    result := get_unused_token(lexer);
    result.type = .IDENT;

    name := parse_ident(lexer, result);
    cached_make_atom(lexer, name, result);

    set_end_of_token(lexer, result);

    keyword_type := check_for_keyword(result);
    if keyword_type result.type = keyword_type;

    return result;
}

make_hexfloat :: (lexer: *Lexer, result: *Token) -> *Token {
    result.value_flags |= .FLOAT;
    result.value_flags |= .NUMBER;
    result.value_flags |= .HEX;

    digit_accumulator: u64;
    num_digits: s32;

    DIGITS_MAX :: 16;

    while 1 {
        c := peek_next_character(lexer);
        if c == #char "_" {
            eat_character(lexer);
            continue;
        }

        digit_value: u32;

        // @Cutnpaste get_hex_digit.
        if      (c >= #char "a") && (c <= #char "f") digit_value = cast(u32)(10 + c - #char "a");
        else if (c >= #char "A") && (c <= #char "F") digit_value = cast(u32)(10 + c - #char "A");
        else if (c >= #char "0") && (c <= #char "9") digit_value = cast(u32)(c - #char "0");
        else break;

        eat_character(lexer);

        if num_digits == DIGITS_MAX {
            report_parse_error(lexer, "Hexfloat is too long! (16 character maximum.)\n");
        }

        digit_accumulator *= 16;
        digit_accumulator += digit_value;

        num_digits += 1;
    }

    if num_digits == 0 {
        report_parse_error(lexer, "Expected some hexadecimal characters after \"0h\", but found none.\n");
    } else if (num_digits != 4) && (num_digits != 8) && (num_digits != 16) {
        report_parse_error(lexer, "Numbers designated by 0h must be 4, 8 or 16 digits; this one is %d digits.\n", num_digits);
    }

    if num_digits > 8 {
        result.value_flags |= .REQUIRES_FLOAT64;

        assert(size_of(type_of(digit_accumulator)) == size_of(float64));

        union {
            _f64: float64;
            _u64: u64;
        };

        _u64 = digit_accumulator;
        result.float64_value = _f64;
    } else if num_digits == 8 {
        union {
            _f32: float32;
            _u32: u32;
        };

        _u32 = cast(u32)digit_accumulator;
        result.float64_value = _f32;  // We store it in a float64, but the float32 information is exact ... hopefully.
    } else {
        union {
            _f32: float32;
            _u32: u32;
        };

        _u32 = cast(u32)cast(u16)digit_accumulator;
        result.float64_value = _f32;  // We store it in a float64, but the float32 information is exact ... hopefully.
    }

    set_end_of_token(lexer, result);
    return result;
}

make_number :: (lexer: *Lexer) -> *Token {
    result := get_unused_token(lexer);
    result.type = .NUMBER;


    result_can_only_be_u64_if_it_is_an_integer_at_the_end := false;

    buffer := lexer.scratch_buffer.data;
    cursor := buffer;

    buffer_len: s32 = MAX_IDENTIFIER_LENGTH;

    after_decimal_cursor: *u8;
    exponent_cursor: *u8;

    numeric_flags: Value_Flags;
    digit_accumulator: u64;

    all_fs: u64 : 0xffff_ffff_ffff_ffff;
    all_fs_div10 :: all_fs/10;
    all_fs_div16 :: all_fs/16;
    all_fs_div2  :: all_fs/2;

    overflow_check_lower_bound := all_fs_div10; // We start in base 10, but may switch this if we change the base.

    while cursor < buffer + buffer_len - 1 {
        c := peek_next_character(lexer);

        if (cursor == buffer + 1) && (<<buffer == #char "0") && !numeric_flags {  // if numeric_flags is nonzero, we already did a prefix!
            if (c == #char "x") || (c == #char "X") {
                // Maybe it"s a hex number.
                numeric_flags |= .HEX;
                eat_character(lexer);
                cursor = buffer;  // Take the leading 0 out.
                continue;
            } else if (c == #char "b") || (c == #char "B") {
                // Maybe it"s a binary number.
                numeric_flags |= .BINARY;
                eat_character(lexer);
                cursor = buffer;  // Take the leading 0 out.
                continue;
            } else if (c == #char "h") || (c == #char "H") {
                // Maybe it"s a hexfloat.
                eat_character(lexer);
                return make_hexfloat(lexer, result);
            }
        }

        if c == #char "_" {
            eat_character(lexer);
            continue;
        }

        if c == #char "." {
            eat_character(lexer);

            c = peek_next_character(lexer);
            if c == #char "." {
                // Uhh.. this isn"t a decimal, it"s part of an integer range
                // specifier, e.g.:  (1..3)
                // so we are going to return an integer here and push
                // a #char ".." token into the token queue.

                unwind_one_character(lexer);
                break;
            } else {
                if after_decimal_cursor {
                    set_end_of_token(lexer, result);
                    report_parse_error(lexer, "Can't have two decimals in a number!\n");
                    break;
                }

                if numeric_flags & .HEX {
                    set_end_of_token(lexer, result);
                    report_parse_error(lexer, "Cannot use a decimal point in a hexadecimal number!\n");
                }

                if numeric_flags & .BINARY {
                    set_end_of_token(lexer, result);
                    report_parse_error(lexer, "Cannot use a decimal point in a binary number!\n");
                }

                cursor.* = #char ".";
                cursor += 1;

                after_decimal_cursor = cursor;
                numeric_flags |= .FLOAT;
                continue;
            }
        } else {
            if after_decimal_cursor {
                // We will translate at the end using atof.
                if !is_digit(cast(u8)c) {
                    if (c == #char "f") {
                        set_end_of_token(lexer, result);
                        report_parse_error(lexer, result, "In this language, we don't suffix our float constants with f.\n");
                    }

                    // Handle e+ or e- whatever.
                    if ((c|32) == #char "e") {  // Supports capital E as well.
                        if exponent_cursor {
                            set_end_of_token(lexer, result);
                            report_parse_error(lexer, result, "Can't have two exponents in a number!\n");
                            break;
                        }

                        exponent_cursor = cursor;
                        <<cursor = #char "e";
                        cursor += 1;

                        eat_character(lexer);
                        c = peek_next_character(lexer);
                        if (c == #char "+") || (c == #char "-") {
                            // We have to check because we are adding more than one character!
                            if cursor <= buffer + buffer_len - 1 {
                                <<cursor = cast(u8) c;
                                cursor += 1;
                                eat_character(lexer);
                            }

                            continue;
                        } else if is_digit(cast(u8) c) {
                            continue;
                        } else {
                            // printf("c is %c\n", c);
                            set_end_of_token(lexer, result);
                            report_parse_error(lexer, result, "'e' in a float literal must be followed by + or - or a numerical digit.\n");
                            break;
                        }
                    }

                    break;
                }
            } else {
                accepted := false;

                digit_value: u32;
                base: u32 = 10;

                if is_digit(cast(u8) c) {
                    accepted = true;
                    digit_value = cast(u32) (c - #char "0");
                }

                if numeric_flags & .HEX {
                    base = 16;
                    overflow_check_lower_bound = all_fs_div16;

                    if (c >= #char "a") && (c <= #char "f") {
                        accepted = true;
                        digit_value = cast(u32)(10 + (c - #char "a"));
                    }

                    if (c >= #char "A") && (c <= #char "F") {
                        accepted = true;
                        digit_value = cast(u32)(10 + (c - #char "A"));
                    }
                } else if numeric_flags & .BINARY {
                    base = 2;
                    overflow_check_lower_bound = all_fs_div2;

                    if (digit_value > 1) {
                        accepted = false;
                        set_end_of_token(lexer, result);
                        report_parse_error(lexer, "Invalid digit in a binary number.\n");
                        break;
                    }
                }

                if accepted {
                    old_value := digit_accumulator;

                    // @Speed: I am sure Hacker's Delight has a faster way to do this?
                    if old_value > overflow_check_lower_bound {
                        numeric_flags |= .OVERFLOWED;
                    }

                    digit_accumulator *= base;

                    pre_add := digit_accumulator;

                    if (digit_accumulator > 0x7fff_ffff_ffff_ffff) && (base == 10) {  // @Speed: Reverse these ifs, because this is less than all our overflow_check_lower_bound values, so we can get away with 1 if statement for almost all numbers.
                        result_can_only_be_u64_if_it_is_an_integer_at_the_end = true;
                    }

                    digit_accumulator += digit_value;
                    if digit_accumulator < pre_add {
                        numeric_flags |= .OVERFLOWED;
                    }

                } else {
                    break;
                }
            }
        }

        eat_character(lexer);
        <<cursor = cast(u8) c;
        cursor += 1;
    }

    <<cursor = #char "\0";

    if after_decimal_cursor {
        // @Incomplete: Sizing for float numbers!
        // The integer thing we do seems pretty successful, so floats should probably
        // just work that way.

        // Note: string_to_float gives us a remainder string, so if
        // we wanted to and felt it would work with all the required nuances,
        // we could refactor to use that and simplify this code.

        t: string;
        t.data = buffer;
        t.count = cursor - buffer;
        f64_value := string_to_float64(t);

        //
        // We want to find the number of significant digits,
        // so we can decide the default size of the number.
        // This is probably too complex to be the right thing to do.
        //
        significant_figures: s32;
        end := exponent_cursor;
        if !end end = cursor;

        while end > after_decimal_cursor {
            p := <<(end - 1);
            if (p != #char "0") && (p != #char "_") break;

            end -= 1;
        }

        begin := buffer;
        while begin < end {
            b := <<begin;
            if (b != #char "0") && (b != #char "_") && (b != #char ".") break;  // We don't worry about +, -, etc.
            begin += 1;
        }

        s := begin;
        while s < end {
            c := <<s;
            if (c >= #char "0") && (c <= #char "9") significant_figures += 1;
            s += 1;
        }

        // @Incomplete: Account for digits that come before the decimal.
        // Remove trailing zeroes.

        use_float64 := false;
        if significant_figures > 8 {  // @Hack! Find the right thing here. @Cleanup.
            use_float64 = true;
            result.value_flags |= .REQUIRES_FLOAT64_DUE_TO_SIGNIFICANT_DIGITS;
        } else {
            use_float64 |= has_a_big_exponent(f64_value);
        }

        if use_float64 {
            result.value_flags |= .REQUIRES_FLOAT64;
        } else {
            if significant_figures >= 8 {
                result.value_flags |= .DEFAULTS_TO_FLOAT64;
            }
        }

		result.float64_value = f64_value;
    } else {
        // We don't use 'buffer', as we translated it ourselves.
        result.integer_value = digit_accumulator;

        if result_can_only_be_u64_if_it_is_an_integer_at_the_end {
            // This can only be u64. We don't have a special flag for this, so for now
            // use HEX, though that will confuse Program_Print etc.

            // We can't put the HEX in the loop above because we don't want it to affect parsing.
            // We are just setting it to hack the output.

            // @Cleanup.

            numeric_flags |= .HEX;
        }
    }

    result.value_flags |= numeric_flags | .NUMBER;

    set_end_of_token(lexer, result);

    if (numeric_flags & .OVERFLOWED) && !(numeric_flags & .FLOAT) {
        report_parse_error(lexer, result, "Integer literal is too big. All integer literals must fit into 64 bits.\n");
    }

    return result;
}

make_string_constant :: (lexer: *Lexer) -> *Token {
    result := get_unused_token(lexer);
    result.type = .STRING;

    eat_character(lexer);  // We only get here if we saw a single quote.

    builder: String_Builder;
    while 1 {
        c := peek_next_character(lexer);
        eat_character(lexer);

        if c == #char "\"" {
            break;
        }

		if c == -1 {
			report_parse_error(lexer, "End of file during string constant!\n");
			break;
		}

        if c == #char "\n" {
            report_parse_error(lexer, "Newline in string constant!\n");
            break;
        }

        if c == #char "\\" {
            // @Robustness: add support for more escapes sequences

            next := peek_next_character(lexer);
            if next == #char "n" {
                c = #char "\n";
                eat_character(lexer);
            } else if next == #char "r" {
                c = #char "\r";
                eat_character(lexer);
            } else if next == #char "t" {
                c = #char "\t";
                eat_character(lexer);
            } else if next == #char "0" {
                c = 0;
                eat_character(lexer);
            } else if next == #char "e" {
                c = 0x1B;
                eat_character(lexer);
            } else if next == #char "x" {
                eat_character(lexer);
                // If get_hex_digit failed, we issued an error,
                // so we don't worry about the value of c in that case.
                high := get_hex_digit(lexer, .ASCII_8_BIT);
                low  := get_hex_digit(lexer, .ASCII_8_BIT);
                c = cast(s16)(high * 16 + low);
            } else if next == #char "d" {
                eat_character(lexer);
                // get_decimal_digit returns -1 on failure. If so, we issued an error,
                // so we don't worry about the value of c.
                high := get_decimal_digit(lexer);
                if high >= 0 {
                    middle := get_decimal_digit(lexer);
                    if middle >= 0 {
                        low := get_decimal_digit(lexer);
                        if low < 0  low = 0;
                        c = cast(s16)(high * 100 + middle * 10 + low);
                        if c > 255 {
                            l0 := lexer.current_line_number;
                            l1 := l0;
                            c0 := lexer.current_character_index - 3;
                            c1 := lexer.current_character_index;
                            // @Cleanup report_error(*lexer, l0, c0, l1, c1, lexer.active_load, "Decimal value of %d exceeds the limit of 255.\n", c);
                            lexer.reported_error = true;  // @Hack
                        }
                    }
                }
            } else if (next == #char "u") || (next == #char "U") {
                eat_character(lexer);

                num_digits: s32 = 4;
                type := Hex_Digit_Type.UNICODE_16;
                if next == #char "U" {
                    num_digits = 8;
                    type = .UNICODE_32;
                }

                value: u32;
                for i: 0..num_digits-1 {
                    digit, success := get_hex_digit(lexer, type);
                    if !success break;

                    value <<= 4;
                    value += digit;
                }

                LEN_MAX :: 4;
                buf: [LEN_MAX] u8;

                s: string;
                s.data = buf.data;

                character_utf32_to_utf8(value, *s);
                append(*builder, s);

                continue;  // NOTE: Do not fall through to the bottom.
            } else if next == #char "\"" {
                c = #char "\"";
                eat_character(lexer);
            } else if next == #char "\\" {
                c = #char "\\";
                eat_character(lexer);
            } else if next == #char "%" {
                c = 31;
                eat_character(lexer);
            } else {
                // @Cleanup reporinterp.report(REPORT_WARNING, lexer, null, "Unknown escape sequence '\\%c' in string constant!", next);
                c = next;
                eat_character(lexer);
            }
        }

        // NOTE: In the case of Unicode characters, we continue
        // rather than falling through to the bottom, so don't depend
        // on that!
        append(*builder, cast(u8) c);
    }

    append(*builder, 0);  // Zero-terminate the string!

    data := builder_to_string(*builder);
    data.count -= 1;   // Don't count the zero-termination in the length.

    if data {
        result.string_value = data;
    } else {
        // :EmptyStringLiteral
        // Later stages of the compiler require string literals to have null data pointers,
        // so let's start early.
        result.string_value = "";
    }

    set_end_of_token(lexer, result);

    return result;
}

make_one_character_token :: (lexer: *Lexer, c: Token_Type) -> *Token {
    // Should be called after eat_character. We subtract 1 from the
    // starting character index to account for that.  @Speed

    result := get_unused_token(lexer);
    result.type = c;
    result.c0 -= 1;

    set_end_of_token(lexer, result);

    return result;
}

count_herestring_lines :: (lexer: *Lexer, token: *Token) -> s64 {
    line := token.l1;
    assert(line != -1);
    assert(line >= lexer.previous_token_line_number);

    net_lines := 0;
    if line > lexer.previous_token_line_number {
        net_lines = (token.l1 - token.l0) + 1;
        lexer.nonblank_lines_processed += net_lines + 1;  // Extra +1 for herestring terminator.
        lexer.previous_token_line_number = line + 1;  // +1 for herestring terminator.
    }

    return net_lines;
}

eat_token :: (lexer: *Lexer) {
    assert(lexer.num_incoming_tokens > 0);

    assert((MAX_CONCURRENT_TOKENS & (MAX_CONCURRENT_TOKENS - 1)) == 0);  // Assert that it's a power of two.

    {  // @Simplify: a herestring is the only thing that can be multiline right now (I think), and it is handled in count_herestring_lines!
        token := *lexer.tokens[lexer.token_array_cursor];
        line := token.l1;
        assert(line != -1);
        assert(line >= lexer.previous_token_line_number);

        if line > lexer.previous_token_line_number {
            lexer.nonblank_lines_processed += (token.l1 - token.l0) + 1;
            lexer.previous_token_line_number = line;
        }
    }

    lexer.num_incoming_tokens -= 1;
    lexer.token_array_cursor = (lexer.token_array_cursor + 1) & (MAX_CONCURRENT_TOKENS - 1);
}

check_for_equals :: (lexer: *Lexer, c: Token_Type, augmented: Token_Type, eat := true, subtractor: s32 = 0) -> *Token {
    // subtractor is the base token width minus one, for ... reasons ... @Cleanup.
    result: *Token;
    if eat eat_character(lexer);

    next := peek_next_character(lexer);
    if next == #char "=" {
        eat_character(lexer);
        result = make_one_character_token(lexer, augmented);
        result.c0 -= (subtractor + 1);
    } else {
        result = make_one_character_token(lexer, c);
        result.c0 -= subtractor;
    }

    return result;
}

//
// @Robustness: We might want to modify eat_input_due_to_block_comment so that
// characters in front of comment items need to be clear... e.g. right now it considers
// the string "/////*" to be a nested open-comment... not sure if we want that.
//
eat_input_due_to_block_comment :: (lexer: *Lexer) {
    comment_depth: s32 = 1;

    while comment_depth {
        c := peek_next_character(lexer);

        if c == -1 { // End of input!
            report_parse_error(lexer, "End of input from within a comment.\n");  // XXX Do a real error message here...
            return;
        }

        if c == #char "/" {
            eat_character(lexer);
            c := peek_next_character(lexer);
            if c == #char "*" {
                eat_character(lexer);
                comment_depth += 1;
            }
        } else if c == #char "*" {
            eat_character(lexer);
            c := peek_next_character(lexer);
            if c == #char "/" {
                eat_character(lexer);
                comment_depth -= 1;
            }
        } else {
            eat_character(lexer);
        }
    }
}

eat_until_newline :: (lexer: *Lexer) {
    // Eat until newline or end-of-input or zero
/*
#if USE_SIMD
    __m128i newline = _mm_set1_epi8('\n";
    while (lexer.input.count - lexer.input_cursor >= LEXER_SIMD_WIDTH) {
        __m128i characters = _mm_loadu_si128  ((__m128i *)(lexer.input.data + lexer.input_cursor));
        __m128i test       = _mm_cmpeq_epi8   (characters, newline);
        int     mask       = _mm_movemask_epi8(test);
        if (mask) {
            // We found a newline.
            auto advance = _tzcnt_u32(mask) + 1;  // +1 for the newline.
            lexer.input_cursor += advance;
            lexer.current_character_index = 1;
            lexer.current_line_number += 1;
            lexer.total_lines_processed += 1;
            return;
        } else {
            lexer.input_cursor            += 16;
            lexer.current_character_index += 16;
        }
    }

    if (lexer.input_cursor == lexer.input.count) return;
#endif // USE_SIMD
*/

    c: s32;
    while 1 {
        c = peek_next_character(lexer);
        if c == 0 break;
        if c == #char "\n" break;
        if c == -1 break;
        eat_character(lexer);
    }
}

is_whitespace :: (c: u8) -> bool {
    return c == #char " " || c == #char "\t" || c == #char "\r";
}

compose_new_token :: (lexer: *Lexer) -> *Token {
    while 1 {
        // We used to recurse by calling compose_new_token further, but that is
        // not so great  -= 1 at least in theory you could compose an input that
        // would cause a stack overflow. So instead, we loop, and return
        // when we find a good token.

        c := peek_next_character(lexer);


        while (c != -1) && is_whitespace(cast(u8) c) { // @Cleanup
            eat_character(lexer);
            c = peek_next_character(lexer);
        }

        if c == -1 {
            return make_one_character_token(lexer, .END_OF_INPUT);
        }

        if starts_identifier(cast(u8) c) {
            return make_ident_or_keyword(lexer);
        }

        if c == #char "`" {
            eat_character(lexer);
            c = peek_next_character(lexer);
            if !starts_identifier(cast(u8) c) {
                report_parse_error(lexer, "Expected an identifier after '`'.\n");
            }

            token := make_ident_or_keyword(lexer);  // Should return an empty ident if we parse errored above.
            if (token.type == .IDENT) || (token.type == .KEYWORD_DEFER) || (token.type == .KEYWORD_RETURN) || (token.type == .KEYWORD_OPERATOR) || (token.type == .KEYWORD_PUSH_CONTEXT) {
                token.ident_is_backticked = true;
            } else {
                report_parse_error(lexer, "Expected an identifier after '`', but '%s' is a keyword. ('defer', 'return', 'push_context' and overloaded operator functions are the only keywords that can be backticked.)\n", token.ident_value.name);
            }

            return token;
        }

        if c == #char "." {
            // Check for double-dot... but if it is not specifically double-dot
            // then it might be a single-dot, and it might be a floating-point
            // number...

            eat_character(lexer);
            c = peek_next_character(lexer);
            if c == #char "." {
                eat_character(lexer);
                token := make_one_character_token(lexer, .DOUBLE_DOT);
                token.c0 -= 1; // Include the previous dot
                return token;
            } else if c == #char "*" {
                eat_character(lexer);
                token := make_one_character_token(lexer, .POSTFIX_DEREFERENCE);
                token.c0 -= 1; // Include the previous dot
                return token;
            } else if c == #char "?" {
                eat_character(lexer);
                token := make_one_character_token(lexer, .CONDITIONAL_DEREFERENCE);
                token.c0 -= 1; // Include the previous dot
                return token;
            } else if c == #char "[" {
                eat_character(lexer);
                token := make_one_character_token(lexer, .BEGIN_ARRAY_LITERAL);
                token.c0 -= 1; // Include the previous dot
                return token;
            } else if c == #char "{" {
                eat_character(lexer);
                token := make_one_character_token(lexer, .BEGIN_STRUCT_LITERAL);
                token.c0 -= 1; // Include the previous dot
                return token;
            }

            if is_digit(cast(u8) c) {
                unwind_one_character(lexer);  // Get the '.' back.
                return make_number(lexer);
            }

            return make_one_character_token(lexer, #char ".");
        }

        if starts_number(cast(u8) c) {
            return make_number(lexer);
        }

        result: *Token;
        if c == {
        case #char "(";  #through;
        case #char ")";  #through;
        case #char ";";  #through;
        case #char "[";  #through;
        case #char "]";  #through;
        case #char "'"; #through;
        case #char "\n"; #through;
        case;
            eat_character(lexer);
            result = make_one_character_token(lexer, cast(Token_Type) c);
        case 0xE2;
            orig_pos := lexer.input.data + lexer.input_cursor;

            u, consumed_length, conv_result := character_utf8_to_utf32(orig_pos, lexer.input.count - lexer.input_cursor);

            if conv_result == .CONVERSION_OK {
                lexer.input_cursor += consumed_length;

                if u == {
                case 0x200B;
                    // @Cleanup interp.report(REPORT_WARNING, lexer, null, "Illegal Unicode zero-width space found in the program text. This could be a problem with pasting the data from another source.\n");
                    return compose_new_token(lexer);
                case 0x2066; #through;
                case 0x2067; #through;
                case 0x2068; #through;
                case 0x202A; #through;
                case 0x202B; #through;
                case 0x202D; #through;
                case 0x202E; #through;
                case 0x2069; #through;
                case 0x202C;
                    // @Cleanup interp.report(REPORT_WARNING, lexer, null, "Illegal Unicode directional-formatting character found in the program text. This could be a problem with pasting the data from another source.\n");
                    return compose_new_token(lexer);
                case;
                    report_parse_error(lexer, "Unicode characters in this range are not supported by the parser at lexer time. (Offending character code was U+%x.\n", u);
                    return compose_new_token(lexer);
                }

                result = make_one_character_token(lexer, cast(Token_Type) u);
            } else {
                report_parse_error(lexer, "Attempted to parse a Unicode character here, but was unable to read a whole valid character.\n");
                result = make_one_character_token(lexer, 0);  // @Cleanup?
            }
        case #char "#";
            eat_character(lexer);
            if lexer.current_character_index == 2 {  // @Cleanup: Why 2 instead of 1? I guess the index is 1 after the character we are peeking?^
                c := peek_next_character(lexer);
                if c == #char "!" {
                    // It's a hashbang. Skip the whole line.
                    eat_until_newline(lexer);
                    continue;
                }
            }

            next := peek_next_token(lexer);
            if (next.type == .IDENT) && (next.ident_value.name == "string") {
                // In the C++ version of the Lexer, the Parser actually invokes lexing of
                // a here-string when it sees '%' followed by 'string'. Since we don't
                // have a Parser here, we do this ourselves.
                eat_token(lexer);
                result = parse_here_string(lexer);
                lexer.previous_token_line_number = result.l1;  // @Cleanup @Hack
            } else {
                result = make_one_character_token(lexer, cast(Token_Type) c);
            }
        case #char "&";
            eat_character(lexer);
            other_c := peek_next_character(lexer);
            if other_c == #char "&" {
                eat_character(lexer);
                result = check_for_equals(lexer, .LOGICAL_AND, .LOGICAL_AND_EQUALS, false, 1);
            } else {
                result = check_for_equals(lexer, cast(Token_Type) c, .BITWISE_AND_EQUALS, false);
            }
        case #char "|";
            eat_character(lexer);
            other_c := peek_next_character(lexer);
            if other_c == #char "|" {
                eat_character(lexer);
                result = check_for_equals(lexer, .LOGICAL_OR, .LOGICAL_OR_EQUALS, false, 1);
            } else {
                result = check_for_equals(lexer, cast(Token_Type) c, .BITWISE_OR_EQUALS, false);
            }
        case #char "+";
            result = check_for_equals(lexer, cast(Token_Type) c, .PLUSEQUALS);
        case #char "-"; {
            eat_character(lexer);

            next := peek_next_character(lexer);
            if next == #char ">" {
                eat_character(lexer);
                result = make_one_character_token(lexer, .RIGHT_ARROW);
                result.c0 -= 1;
            } else if next == #char "-" {
                eat_character(lexer);
                next = peek_next_character(lexer);

                if next == #char "-" {
                    eat_character(lexer);
                    result = make_one_character_token(lexer, .TRIPLE_MINUS);
                    result.c0 -= 2;
                } else {
                    result = make_one_character_token(lexer, .DOUBLE_MINUS);
                    result.c0 -= 1;
                }

            } else {
                unwind_one_character(lexer);  // @Hack because check_for_equals calls eat_character immediately.
                result = check_for_equals(lexer, cast(Token_Type) c, .MINUSEQUALS);
            }
        }
        case #char "*";
            result = check_for_equals(lexer, cast(Token_Type) c, .TIMESEQUALS);
        case #char "%";
            result = check_for_equals(lexer, cast(Token_Type) c, .MODEQUALS);
        case #char "/";
            eat_character(lexer);
            c = peek_next_character(lexer);
            if c == #char "/" {
                eat_character(lexer);

                eat_until_newline(lexer);

                continue;
            } else if c == #char "*" {
                eat_character(lexer);
                eat_input_due_to_block_comment(lexer);
                continue;
            } else if c == #char "=" {
                eat_character(lexer);
                result = make_one_character_token(lexer, .DIVEQUALS);
                result.c0 -= 1;
            } else {
                result = make_one_character_token(lexer, #char "/");
            }
        case #char "!";
            result = check_for_equals(lexer, cast(Token_Type) c, .ISNOTEQUAL);
        case #char ",";
            eat_character(lexer);
            next := peek_next_character(lexer);

            if next == #char "," {
                eat_character(lexer);
                result = make_one_character_token(lexer, .DOUBLE_COMMA);
                result.c0 -= 1;
            } else {
                result = make_one_character_token(lexer, #char ",");
            }

        case #char "="; {
            eat_character(lexer);
            next := peek_next_character(lexer);
            if next == #char "=" {
                eat_character(lexer);
                next = peek_next_character(lexer);
                if next == #char "=" {
                    eat_character(lexer);
                    result = make_one_character_token(lexer, .TRIPLE_EQUALS);
                    result.c0 -= 2;
                } else {
                    result = make_one_character_token(lexer, .ISEQUAL);
                    result.c0 -= 1;
                }
            } else if next == #char ">" {
                eat_character(lexer);
                result = make_one_character_token(lexer, .QUICK_LAMBDA);
                result.c0 -= 1;
            } else {
                result = make_one_character_token(lexer, #char "=");
            }
        }
        case #char "^"; {
            eat_character(lexer);
            result = check_for_equals(lexer, cast(Token_Type) c, .BITWISE_XOR_EQUALS, false);
        }
        case #char "~";
            eat_character(lexer);
            result = make_one_character_token(lexer, .BITWISE_NOT);
        case #char "<"; {
            eat_character(lexer);
            next := peek_next_character(lexer);
            if next == #char "<" {
                eat_character(lexer);
                next := peek_next_character(lexer);
                if next == #char "<" {
                    eat_character(lexer);
                    result = check_for_equals(lexer, .ROTATE_LEFT, .ROTATE_LEFT_EQUALS, false, 2);
                } else {
                    result = check_for_equals(lexer, .POINTER_DEREFERENCE_OR_SHIFT_LEFT, .SHIFT_LEFT_EQUALS, false, 1);
                }
            } else {
                result = check_for_equals(lexer, cast(Token_Type) c, .LESSEQUALS, false);
            }
        }
        case #char ">"; {
            eat_character(lexer);
            next := peek_next_character(lexer);
            if next == #char ">" {
                eat_character(lexer);
                next := peek_next_character(lexer);
                if next == #char ">" {
                    eat_character(lexer);
                    result = check_for_equals(lexer, .ROTATE_RIGHT, .ROTATE_RIGHT_EQUALS, false, 2);
                } else {
                    result = check_for_equals(lexer, .SHIFT_RIGHT, .SHIFT_RIGHT_EQUALS, false, 1);
                }
            } else {
                result = check_for_equals(lexer, cast(Token_Type) c, .GREATEREQUALS, false);
            }
        }
        case #char "?";
            eat_character(lexer);
            result = make_one_character_token(lexer, #char "?");
        case #char "{";
            eat_character(lexer);
            result = make_one_character_token(lexer, #char "{");
        case #char "$";
            eat_character(lexer);

            other_c := peek_next_character(lexer);
            doubled := false;
            if other_c == #char "$" {
                eat_character(lexer);
                doubled = true;
            }

            if doubled {
                result = make_one_character_token(lexer, .DOUBLE_DOLLAR);
                result.c0 -= 1;  // @Hack!
            } else {
                result = make_one_character_token(lexer, #char "$");
            }
        case #char "@";  // "
            eat_character(lexer);
            other_c := peek_next_character(lexer);
            if other_c == #char "\"" {
                result := make_string_constant(lexer);
                if !result break;

                // @Hack: Overwrite this to a Note token.
                // This will change later when we do structured notes,
                // probably.

                result.type = .NOTE;
                cached_make_atom(lexer, result.string_value, result);

                return result;
            }

            return make_note(lexer); // Old-style note where we just parse from the @ until whitespace.
        case #char "\"";
            result = make_string_constant(lexer);
        case 0xc2;
            eat_character(lexer);
            other_c := peek_next_character(lexer);
            if other_c == 0xa0 {  // Unicode non-breaking space.
/*
                if (!did_nbsp_warning) {
                    // Don't spam!
                    interp.report(REPORT_WARNING, this, null, "A Unicode non-breaking space character is here, outside of a string. Skipping.\n");
                    did_nbsp_warning = true;
                }
*/

                eat_character(lexer);
                continue;
            }

            result = make_one_character_token(lexer, cast(Token_Type) c);
        }

        assert(result != null);
        return result;
    }
}

peek_token :: (lexer: *Lexer, lookahead_index: s32) -> *Token {
    assert(lookahead_index <  MAX_CONCURRENT_TOKENS);
    assert(lookahead_index >= 0);

    if lookahead_index == 0 return peek_next_token(lexer);

    while lexer.num_incoming_tokens <= lookahead_index {
		if lexer.reported_error {
			eof := *lexer.eof_token;
            set_end_of_token(lexer, eof);
            eof.l0 = eof.c0;
            eof.l1 = eof.c1;
            return eof;
		}

        compose_new_token(lexer);
        lexer.num_incoming_tokens += 1;
    }

    index := (lexer.token_array_cursor + lookahead_index) & (MAX_CONCURRENT_TOKENS - 1);
    return *lexer.tokens[index];
}

set_input_from_string :: (lexer: *Lexer, input: string) {
    if lexer.should_free_input  free(lexer.input);

    lexer.input = input;
    lexer.input_cursor = 0;
    lexer.should_free_input = false;

    lexer.current_line_number = 1;
    lexer.current_character_index = 1;
    lexer.previous_token_line_number = 0;
//    did_nbsp_warning = false;

    // @Incomplete: Push these tokens until later?
    lexer.num_incoming_tokens = 0;  // @Leak of whatever tokens were waiting.
}

set_input_from_file :: (lexer: *Lexer, file_path: string) -> bool {
    //
    // :AtomTableInit
    //
    // @Speed: Use some heuristic to size the atom table so
    // we don't pay for expansions?
    //

    assert(file_path != "");

    // @Incomplete: Push these tokens until later?
    lexer.num_incoming_tokens = 0;  // @Leak of whatever tokens were waiting.

    value, success := read_entire_file(file_path, true, true);
    if !success  return false;

    if lexer.should_free_input free(lexer.input);
    lexer.should_free_input = true;

    lexer.input = value;
    lexer.input_cursor = 0;

    lexer.current_line_number = 1;
    lexer.current_character_index = 1;
    lexer.previous_token_line_number = 0;
//    did_nbsp_warning = false;

	return true;
}

has_a_big_exponent :: inline (value: float64) -> bool {
    // Return true if this is exponent too big to fit into float32.
    union {
        _f64: float64;
        _s64: s64;
    };

    _f64 = value;

    exponent := (_s64 >> 52) & 0x7ff;

    if (exponent != 0) && (exponent != 0x7ff) {
        exponent -= 1023;
        return (exponent > 127) || (exponent < -126);
    }

    return false;
}

